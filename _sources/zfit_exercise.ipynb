{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfbe2750-c19b-44de-b1ae-23d8eddee39b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5f2f89f-26d6-4d80-93bf-c4a70f030dba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## common parameters and imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zfit\n",
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Set a seed for reproducibility (so every student gets the same data)\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Configuration ---\n",
    "# True Physics Parameters\n",
    "BR_true = 5.8e-6 \n",
    "alpha_Ds = 2.5e-9\n",
    "alpha_Dp = 8.0e-9\n",
    "\n",
    "# Yields\n",
    "N_sig_Ds = int(BR_true / alpha_Ds) # ~2320 events\n",
    "N_sig_Dp = int(BR_true / alpha_Dp) # ~725 events\n",
    "\n",
    "# Mass Parameters (MeV)\n",
    "m_Ds = 1968.0\n",
    "m_Dp = 1869.6\n",
    "m_eta = 547.8\n",
    "\n",
    "# Resolution (sigma)\n",
    "sigma_D = 15.0\n",
    "sigma_eta = 10.0\n",
    "\n",
    "# Background Slopes (Exponential index)\n",
    "slope_Ds_D = -0.002\n",
    "slope_Dp_D = -0.003\n",
    "slope_eta = -0.005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e293b0-9176-42bf-a354-8a1719ae10bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets generated:\n",
      "- dataset_Ds.csv (5820 events)\n",
      "- dataset_Dp.csv (3125 events)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_Ds_sample(n_sig, n_comb, n_peaking):\n",
    "    # 1. Signal (Ds -> eta pi): Gaussian(Ds) * Gaussian(eta)\n",
    "    sig_mD = np.random.normal(m_Ds, sigma_D, n_sig)\n",
    "    sig_mEta = np.random.normal(m_eta, sigma_eta, n_sig)\n",
    "    \n",
    "    # 2. Combinatorial Bkg: Exponential(Ds) * Exponential(eta)\n",
    "    bkg_mD = np.random.exponential(-1/slope_Ds_D, n_comb * 5) + 1800\n",
    "    bkg_mD = bkg_mD[(bkg_mD > 1800) & (bkg_mD < 2100)][:n_comb]\n",
    "    \n",
    "    bkg_mEta = np.random.exponential(-1/slope_eta, n_comb * 5) + 500\n",
    "    bkg_mEta = bkg_mEta[(bkg_mEta > 500) & (bkg_mEta < 600)][:n_comb]\n",
    "    \n",
    "    # 3. Peaking Bkg (Real eta, Fake Ds): Exponential(Ds) * Gaussian(eta)\n",
    "    peak_mD = np.random.exponential(-1/slope_Ds_D, n_peaking * 5) + 1800\n",
    "    peak_mD = peak_mD[(peak_mD > 1800) & (peak_mD < 2100)][:n_peaking]\n",
    "    peak_mEta = np.random.normal(m_eta, sigma_eta, n_peaking)\n",
    "    \n",
    "    # Combine\n",
    "    mD = np.concatenate([sig_mD, bkg_mD, peak_mD])\n",
    "    mEta = np.concatenate([sig_mEta, bkg_mEta, peak_mEta])\n",
    "\n",
    "    df = pd.DataFrame({\"mass_D\": mD, \"mass_eta\": mEta})\n",
    "    # Shuffle\n",
    "    return df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "def generate_Dp_sample(n_sig, n_comb, n_peaking):\n",
    "    # 1. Signal (D+ -> eta pi): Gaussian(Dp) * Gaussian(eta)\n",
    "    sig_mD = np.random.normal(m_Dp, sigma_D, n_sig)\n",
    "    sig_mEta = np.random.normal(m_eta, sigma_eta, n_sig)\n",
    "    \n",
    "    # 2. Combinatorial Bkg: Exponential(Dp) * Exponential(eta)\n",
    "    bkg_mD = np.random.exponential(-1/slope_Dp_D, n_comb * 5) + 1800\n",
    "    bkg_mD = bkg_mD[(bkg_mD > 1800) & (bkg_mD < 2100)][:n_comb]\n",
    "    \n",
    "    bkg_mEta = np.random.exponential(-1/slope_eta, n_comb * 5) + 500\n",
    "    bkg_mEta = bkg_mEta[(bkg_mEta > 500) & (bkg_mEta < 600)][:n_comb]\n",
    "    \n",
    "    # 3. Peaking Bkg (Real D+, Fake eta): Gaussian(Dp) * Exponential(eta)\n",
    "    peak_mD = np.random.normal(m_Dp, sigma_D, n_peaking)\n",
    "    peak_mEta = np.random.exponential(-1/slope_eta, n_peaking * 5) + 500\n",
    "    peak_mEta = peak_mEta[(peak_mEta > 500) & (peak_mEta < 600)][:n_peaking]\n",
    "    \n",
    "    # Combine\n",
    "    mD = np.concatenate([sig_mD, bkg_mD, peak_mD])\n",
    "    mEta = np.concatenate([sig_mEta, bkg_mEta, peak_mEta])\n",
    "    \n",
    "    df = pd.DataFrame({\"mass_D\": mD, \"mass_eta\": mEta})\n",
    "    return df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Generate and Save\n",
    "df_Ds = generate_Ds_sample(n_sig=N_sig_Ds, n_comb=3000, n_peaking=500)\n",
    "df_Dp = generate_Dp_sample(n_sig=N_sig_Dp, n_comb=2000, n_peaking=400)\n",
    "\n",
    "df_Ds.to_csv(\"dataset_Ds.csv\", index=False)\n",
    "df_Dp.to_csv(\"dataset_Dp.csv\", index=False)\n",
    "\n",
    "print(f\"Datasets generated:\\n- dataset_Ds.csv ({len(df_Ds)} events)\\n- dataset_Dp.csv ({len(df_Dp)} events)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b1adeb-ac62-4e78-9c90-4d3041dc4f67",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise:\n",
    "\n",
    "You are analyzing data from a high-energy physics experiment (like LHCb). You are studying the rare decay of charmed mesons into an $\\eta$ meson and a pion:\n",
    "\n",
    "1. $D_s^+ \\to \\eta \\pi^+$\n",
    "2. $D^+ \\to \\eta \\pi^+$\n",
    "\n",
    "In both cases, the  meson is reconstructed via its dimuon decay mode: : $\\eta \\to \\mu^+ \\mu^-$.\n",
    "Your physics objective is to measure the branching ratio $\\mathcal{B}(\\eta \\to \\mu^+\\mu^-)$.\n",
    "This branching ratio is a fundamental constant of nature and must be the **same** regardless of whether the $\\eta$ meson came from a  $D_s^+$ or a $D^+$.\n",
    "\n",
    "You have two datasets: `dataset_Ds.csv` and `dataset_Dp.csv`. \n",
    "\n",
    "\n",
    "* **Sample A ($D^+_s$):** Events selected near the $D_s^+$ mass.\n",
    "* **Sample B ($D^+$):** Events selected near the $D^+$ mass.\n",
    "\n",
    "Instead of fitting $N_{sig}$ independently and calculating the Branching Ratio (BR) offline, you will perform a Simultaneous Fit to both samples. You will parameterize the signal yield $N_{sig}$ in the fit directly as a function of the physics parameter $\\mathcal{B}(\\eta \\to \\mu\\mu)$ and a normalization factor $\\alpha$ (which includes luminosity, cross-section, and efficiency).\n",
    "\n",
    "$$\\mathcal{B}(\\eta \\to \\mu\\mu) = N_{sig} \\cdot \\alpha \\quad \\Rightarrow \\quad N_{sig}(\\mathcal{B}) = \\frac{\\mathcal{B}}{\\alpha}$$\n",
    "\n",
    "You are given the sensitivity factors $\\alpha$ for each channel:\n",
    "\n",
    "$\\alpha_{D_s} = 2.5 \\times 10^{-5}$\n",
    "\n",
    "$\\alpha_{D^+} = 8.0 \\times 10^{-5}$\n",
    "\n",
    "\n",
    "You are dealing with a 2D problem. The observables are:\n",
    "\n",
    "1. `mass_D`: The invariant mass of the  $\\mu\\mu\\pi$ system.\n",
    "2. `mass_eta`: The invariant mass of the  $\\mu\\mu$ system.\n",
    "\n",
    "This sample contains three components:\n",
    "\n",
    "#### Sample 1:  $D_s^+$ Region\n",
    "\n",
    "This sample contains three components:\n",
    "\n",
    "1. **Signal ($D^+_s \\to \\eta \\pi$):**\n",
    "* `mass_D`: Gaussian (Peak at $m_{D^+_s}$).\n",
    "* `mass_eta`: Gaussian (Peak at $m_\\eta$).\n",
    "\n",
    "\n",
    "2. **Combinatorial Background:**\n",
    "* `mass_D`: Exponential.\n",
    "* `mass_eta`: Exponential.\n",
    "\n",
    "\n",
    "3. **Real $\\eta$ Background (Fake $D^+_s$)**:\n",
    "Contains a real $\\eta$, but combined with a random pion:\n",
    "* `mass_D`: Exponential  (No $D^+_s$ peak).\n",
    "* `mass_eta`: Gaussian (Real $\\eta$ peak).\n",
    "\n",
    "\n",
    "#### Sample 2:  $D^+$ Region\n",
    "\n",
    "This sample contains three components:\n",
    "\n",
    "1. **Signal ($D^+ \\to \\eta \\pi$):**\n",
    "* `mass_D`: Gaussian (Peak at $m_{D^+}$).\n",
    "* `mass_eta`: Gaussian (Peak at $m_\\eta$).\n",
    "\n",
    "\n",
    "2. **Combinatorial Background:**\n",
    "* `mass_D`: Exponential.\n",
    "* `mass_eta`: Exponential.\n",
    "\n",
    "3. **Non-Resonant Background (Real $D^+$):**\n",
    "Contains a real $D^+ \\to \\mu\\mu\\pi$ decay, but the muons are not from an $\\eta$ meson.\n",
    "* `mass_D`: Gaussian (Real $D^+$ peak).\n",
    "* `mass_eta`: Exponential (No $\\eta$ peak).\n",
    "\n",
    "\n",
    "#### Tasks\n",
    "\n",
    "1. **Model Building:** Construct the 2D PDFs for all 6 components (3 for , 3 for ) using `zfit`. Try to discuss the *meaning* or *origin* of each of the components mentioned above.\n",
    "*Hint:* The Signal and the ``Real'' background must share the same  mass shape parameters. The centers of the gaussians should be roughly the masses of the relevant particles. You can assume their widths to the be in the range of 5-20 MeV. The background slopes are small and negative, in the $(-10^{-2},-10^{-3})$ range.\n",
    "2. **Parameterization:** Create a shared parameter `BR_eta_mumu`. Define the signal yields for both samples as composed parameters dependent on this BR.\n",
    "3. **Simultaneous Fit:** Perform a simultaneous fit to both datasets.\n",
    "4. **Validation:** Plot the projections of the fit (Mass  and Mass ) for both samples.\n",
    "5. **Result:** Result: Report the fitted value of $\\mathcal{B}(\\eta \\to \\mu\\mu)$ and its uncertainty. Does it cover the true value?\n",
    "6. **Discuss:** How does the precision you achieve in the BR compare to the current world best? How would you improve it? Is there any effect going into the BR uncertainty you are missing? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beecc17-36c1-4632-ad9e-879436fe9d87",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93a43aa-b752-451c-b95a-50f04cd32f96",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Ds events: 5820\n",
      "Loaded D+ events: 3125\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Import datasets\n",
    "# ==========================================\n",
    "\n",
    "# Define the Observable Spaces\n",
    "obs_D = zfit.Space(\"mass_D\", limits=(1800, 2100))\n",
    "obs_eta = zfit.Space(\"mass_eta\", limits=(500, 600))\n",
    "obs_2D = obs_D * obs_eta\n",
    "\n",
    "# Convert to zfit Data\n",
    "data_Ds = zfit.Data.from_pandas(df_Ds, obs=obs_2D)\n",
    "data_Dp = zfit.Data.from_pandas(df_Dp, obs=obs_2D)\n",
    "\n",
    "# Convert to zfit Data\n",
    "data_Ds = zfit.Data.from_pandas(df_Ds, obs=obs_2D)\n",
    "data_Dp = zfit.Data.from_pandas(df_Dp, obs=obs_2D)\n",
    "\n",
    "print(f\"Loaded Ds events: {data_Ds.n_events.numpy()}\")\n",
    "print(f\"Loaded D+ events: {data_Dp.n_events.numpy()}\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use(hep.style.ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7da30d85-9f33-4ca2-9612-420653d8ee4e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/82jfsqxj6ms7ll1_lj0dmr5r0000gq/T/ipykernel_90885/694317539.py:48: UserWarning: As `copy` is not yet properly implemented, this may fails (for ProductPDF for example?). Thiswill be fixed in the future.\n",
      "  sig_Ds_ext = sig_Ds_2D.create_extended(n_sig_Ds)\n",
      "/var/folders/rx/82jfsqxj6ms7ll1_lj0dmr5r0000gq/T/ipykernel_90885/694317539.py:49: UserWarning: As `copy` is not yet properly implemented, this may fails (for ProductPDF for example?). Thiswill be fixed in the future.\n",
      "  comb_Ds_ext = comb_Ds_2D.create_extended(n_comb_Ds)\n",
      "/var/folders/rx/82jfsqxj6ms7ll1_lj0dmr5r0000gq/T/ipykernel_90885/694317539.py:50: UserWarning: As `copy` is not yet properly implemented, this may fails (for ProductPDF for example?). Thiswill be fixed in the future.\n",
      "  fakeDs_ext = fakeDs_2D.create_extended(n_fakeDs)\n",
      "/var/folders/rx/82jfsqxj6ms7ll1_lj0dmr5r0000gq/T/ipykernel_90885/694317539.py:69: UserWarning: As `copy` is not yet properly implemented, this may fails (for ProductPDF for example?). Thiswill be fixed in the future.\n",
      "  sig_Dp_ext = sig_Dp_2D.create_extended(n_sig_Dp)\n",
      "/var/folders/rx/82jfsqxj6ms7ll1_lj0dmr5r0000gq/T/ipykernel_90885/694317539.py:70: UserWarning: As `copy` is not yet properly implemented, this may fails (for ProductPDF for example?). Thiswill be fixed in the future.\n",
      "  comb_Dp_ext = comb_Dp_2D.create_extended(n_comb_Dp)\n",
      "/var/folders/rx/82jfsqxj6ms7ll1_lj0dmr5r0000gq/T/ipykernel_90885/694317539.py:71: UserWarning: As `copy` is not yet properly implemented, this may fails (for ProductPDF for example?). Thiswill be fixed in the future.\n",
      "  fakeEta_ext = fakeEta_2D.create_extended(n_fakeEta)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Model Building\n",
    "# ==========================================\n",
    "\n",
    "# --- Shared Parameters ---\n",
    "# The Parameter of Interest: Branching Ratio\n",
    "br_eta_mumu = zfit.Parameter(\"BR_eta_mumu\", 6e-6, 1e-6, 1e-5)\n",
    "\n",
    "# D mass shapes\n",
    "mu_Ds = zfit.Parameter(\"mu_Ds\", 1968, 1950, 1980)\n",
    "sigma_Ds = zfit.Parameter(\"sigma_Ds\", 15, 5, 30)\n",
    "lam_Ds_bkg = zfit.Parameter(\"lam_Ds_bkg\", -0.002, -0.01, 0)\n",
    "\n",
    "# D mass shapes\n",
    "mu_Dp = zfit.Parameter(\"mu_Dp\", 1870, 1850, 1890)\n",
    "sigma_Dp = zfit.Parameter(\"sigma_Dp\", 15, 5, 30)\n",
    "lam_Dp_bkg = zfit.Parameter(\"lam_Dp_bkg\", -0.003, -0.01, 0)\n",
    "\n",
    "pdf_Dp_gauss = zfit.pdf.Gauss(mu=mu_Dp, sigma=sigma_Dp, obs=obs_D)\n",
    "pdf_Dp_exp = zfit.pdf.Exponential(lambda_=lam_Dp_bkg, obs=obs_D)\n",
    "\n",
    "pdf_Ds_gauss = zfit.pdf.Gauss(mu=mu_Ds, sigma=sigma_Ds, obs=obs_D)\n",
    "pdf_Ds_exp = zfit.pdf.Exponential(lambda_=lam_Ds_bkg, obs=obs_D)\n",
    "\n",
    "# Shared Eta shape parameters (Resolution is detector driven, should be same)\n",
    "mu_eta = zfit.Parameter(\"mu_eta\", 548, 540, 560)\n",
    "sigma_eta = zfit.Parameter(\"sigma_eta\", 10, 5, 20)\n",
    "\n",
    "# Define eta PDF (reused multiple times)\n",
    "pdf_eta_gauss = zfit.pdf.Gauss(mu=mu_eta, sigma=sigma_eta, obs=obs_eta)\n",
    "pdf_eta_exp_Ds = zfit.pdf.Exponential(lambda_=zfit.Parameter(\"lam_eta_Ds\", -0.005, -0.01, 0), obs=obs_eta)\n",
    "pdf_eta_exp_Dp = zfit.pdf.Exponential(lambda_=zfit.Parameter(\"lam_eta_Dp\", -0.005, -0.01, 0), obs=obs_eta)\n",
    "\n",
    "# --- Sample 1: Ds Model ---\n",
    "\n",
    "# 1. Define Components (Standard PDFs)\n",
    "sig_Ds_2D = zfit.pdf.ProductPDF([pdf_Ds_gauss, pdf_eta_gauss])\n",
    "comb_Ds_2D = zfit.pdf.ProductPDF([pdf_Ds_exp, pdf_eta_exp_Ds])\n",
    "fakeDs_2D = zfit.pdf.ProductPDF([pdf_Ds_exp, pdf_eta_gauss])\n",
    "\n",
    "# 2. Define Yield Parameters\n",
    "# Signal yield is a function of BR!\n",
    "n_sig_Ds = zfit.ComposedParameter(\"n_sig_Ds\", lambda br: br / alpha_Ds, params=br_eta_mumu)\n",
    "n_comb_Ds = zfit.Parameter(\"n_comb_Ds\", 3000, 0, 10000)\n",
    "n_fakeDs = zfit.Parameter(\"n_fakeDs\", 500, 0, 2000)\n",
    "\n",
    "# 3. EXTEND the components individually\n",
    "sig_Ds_ext = sig_Ds_2D.create_extended(n_sig_Ds)\n",
    "comb_Ds_ext = comb_Ds_2D.create_extended(n_comb_Ds)\n",
    "fakeDs_ext = fakeDs_2D.create_extended(n_fakeDs)\n",
    "\n",
    "# 4. Sum them (zfit automatically handles the yields)\n",
    "model_Ds = zfit.pdf.SumPDF([sig_Ds_ext, comb_Ds_ext, fakeDs_ext])\n",
    "\n",
    "\n",
    "# --- Sample 2: D+ Model ---\n",
    "\n",
    "# 1. Define Components\n",
    "sig_Dp_2D = zfit.pdf.ProductPDF([pdf_Dp_gauss, pdf_eta_gauss])\n",
    "comb_Dp_2D = zfit.pdf.ProductPDF([pdf_Dp_exp, pdf_eta_exp_Dp])\n",
    "fakeEta_2D = zfit.pdf.ProductPDF([pdf_Dp_gauss, pdf_eta_exp_Dp])\n",
    "\n",
    "# 2. Define Yield Parameters\n",
    "n_sig_Dp = zfit.ComposedParameter(\"n_sig_Dp\", lambda br: br / alpha_Dp, params=br_eta_mumu)\n",
    "n_comb_Dp = zfit.Parameter(\"n_comb_Dp\", 2000, 0, 10000)\n",
    "n_fakeEta = zfit.Parameter(\"n_fakeEta\", 400, 0, 2000)\n",
    "\n",
    "# 3. EXTEND the components individually\n",
    "sig_Dp_ext = sig_Dp_2D.create_extended(n_sig_Dp)\n",
    "comb_Dp_ext = comb_Dp_2D.create_extended(n_comb_Dp)\n",
    "fakeEta_ext = fakeEta_2D.create_extended(n_fakeEta)\n",
    "\n",
    "# 4. Sum them\n",
    "model_Dp = zfit.pdf.SumPDF([sig_Dp_ext, comb_Dp_ext, fakeEta_ext])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94890878-fcb9-4ef1-9a8d-9f1a5af36d92",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Minimization...\n",
      "Converged: True\n",
      "Valid: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{<zfit.Parameter 'BR_eta_mumu' floating=True value=5.843e-06>: {'error': np.float64(1.285789206733119e-07),\n",
       "  'cl': 0.68268949,\n",
       "  'weightcorr': <WeightCorr.FALSE: False>},\n",
       " <zfit.Parameter 'n_comb_Ds' floating=True value=2995>: {'error': np.float64(72.39653003040432),\n",
       "  'cl': 0.68268949,\n",
       "  'weightcorr': <WeightCorr.FALSE: False>},\n",
       " <zfit.Parameter 'n_fakeDs' floating=True value=476.4>: {'error': np.float64(54.6105467876018),\n",
       "  'cl': 0.68268949,\n",
       "  'weightcorr': <WeightCorr.FALSE: False>},\n",
       " <zfit.Parameter 'mu_Ds' floating=True value=1968>: {'error': np.float64(0.37880453868886993),\n",
       "  'cl': 0.68268949,\n",
       "  'weightcorr': <WeightCorr.FALSE: False>},\n",
       " <zfit.Parameter 'sigma_Ds' floating=True value=15.1>: {'error': np.float64(0.3272761746359562),\n",
       "  'cl': 0.68268949,\n",
       "  'weightcorr': <WeightCorr.FALSE: False>},\n",
       " <zfit.Parameter 'mu_eta' floating=True value=547.7>: {'error': np.float64(0.21668669056455242),\n",
       "  'cl': 0.68268949,\n",
       "  'weightcorr': <WeightCorr.FALSE: False>},\n",
       " <zfit.Parameter 'sigma_eta' floating=True value=10.07>: {'error': np.float64(0.18428556533362817),\n",
       "  'cl': 0.68268949,\n",
       "  'weightcorr': <WeightCorr.FALSE: False>},\n",
       " <zfit.Parameter 'lam_Ds_bkg' floating=True value=-0.001864>: {'error': np.float64(0.00020133039214838305),\n",
       "  'cl': 0.68268949,\n",
       "  'weightcorr': <WeightCorr.FALSE: False>},\n",
       " <zfit.Parameter 'lam_eta_Ds' floating=True value=-0.005116>: {'error': np.float64(0.0006560148706026886),\n",
       "  'cl': 0.68268949,\n",
       "  'weightcorr': <WeightCorr.FALSE: False>},\n",
       " <zfit.Parameter 'n_comb_Dp' floating=True value=2004>: {'error': np.float64(56.259983866174515),\n",
       "  'cl': 0.68268949,\n",
       "  'weightcorr': <WeightCorr.FALSE: False>},\n",
       " <zfit.Parameter 'n_fakeEta' floating=True value=401.1>: {'error': np.float64(42.93602631018019),\n",
       "  'cl': 0.68268949,\n",
       "  'weightcorr': <WeightCorr.FALSE: False>},\n",
       " <zfit.Parameter 'mu_Dp' floating=True value=1869>: {'error': np.float64(0.5947037903506792),\n",
       "  'cl': 0.68268949,\n",
       "  'weightcorr': <WeightCorr.FALSE: False>},\n",
       " <zfit.Parameter 'sigma_Dp' floating=True value=14.49>: {'error': np.float64(0.5589732514585241),\n",
       "  'cl': 0.68268949,\n",
       "  'weightcorr': <WeightCorr.FALSE: False>},\n",
       " <zfit.Parameter 'lam_Dp_bkg' floating=True value=-0.003702>: {'error': np.float64(0.0002980576594696255),\n",
       "  'cl': 0.68268949,\n",
       "  'weightcorr': <WeightCorr.FALSE: False>},\n",
       " <zfit.Parameter 'lam_eta_Dp' floating=True value=-0.005003>: {'error': np.float64(0.000719834159418631),\n",
       "  'cl': 0.68268949,\n",
       "  'weightcorr': <WeightCorr.FALSE: False>}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Simultaneous Fit\n",
    "# ==========================================\n",
    "\n",
    "# Create constraints (optional, e.g., if we knew alpha uncertainty)\n",
    "# Here we just assume alphas are exact constants\n",
    "\n",
    "# Create Simultaneous Loss\n",
    "nll_Ds = zfit.loss.ExtendedUnbinnedNLL(model_Ds, data_Ds)\n",
    "nll_Dp = zfit.loss.ExtendedUnbinnedNLL(model_Dp, data_Dp)\n",
    "simul_nll = nll_Ds + nll_Dp\n",
    "\n",
    "# Minimizer\n",
    "minimizer = zfit.minimize.Minuit()\n",
    "print(\"Starting Minimization...\")\n",
    "result = minimizer.minimize(simul_nll)\n",
    "\n",
    "print(f\"Converged: {result.converged}\")\n",
    "print(f\"Valid: {result.valid}\")\n",
    "\n",
    "# Error estimation\n",
    "result.hesse()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce94db98-8559-4236-abb2-61b547af13f2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "True BR:   5.80e-06\n",
      "Fitted BR: 5.84e-06 +/- 1.29e-07\n",
      "Dev (sig): 0.33 sigma\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to retrieve Space from data zfit.Data: Data obs=('mass_D', 'mass_eta') array=[[1948.64883459  505.84774331]\n [1801.87606257  552.86804195]\n [1969.01277722  556.33975977]\n ...\n [1958.25940443  551.5021189 ]\n [2051.10416549  527.25011039]\n [1952.83044287  585.82124203]]. This can be changed behavior (since zfit 0.11): data can no longer be accessed numpy-like but instead the 'obs' can be used, i.e. strings or spaces. This resembles more closely the behavior of a pandas DataFrame.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mObsIncompatibleError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/zfit/core/data.py:1111\u001b[0m, in \u001b[0;36mData.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1111\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mgetitem_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m errorobs:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/zfit/core/data.py:1183\u001b[0m, in \u001b[0;36mgetitem_obs\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1182\u001b[0m     item \u001b[38;5;241m=\u001b[39m convert_to_obs_str(item)\n\u001b[0;32m-> 1183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/zfit/core/data.py:980\u001b[0m, in \u001b[0;36mData.value\u001b[0;34m(self, obs, axis)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 980\u001b[0m     indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maxes\n\u001b[1;32m    981\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mvalue(indices)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/zfit/core/space.py:1936\u001b[0m, in \u001b[0;36mSpace.with_obs\u001b[0;34m(self, obs, allow_superset, allow_subset)\u001b[0m\n\u001b[1;32m   1935\u001b[0m obs \u001b[38;5;241m=\u001b[39m _convert_obs_to_str(obs)\n\u001b[0;32m-> 1936\u001b[0m coords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_superset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_superset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_subset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_subset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1937\u001b[0m binning \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinning\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/zfit/core/coordinates.py:142\u001b[0m, in \u001b[0;36mCoordinates.with_obs\u001b[0;34m(self, obs, allow_superset, allow_subset)\u001b[0m\n\u001b[1;32m    141\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe requested obs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are not compatible with the current obs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ObsIncompatibleError(msg)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mfrozenset\u001b[39m(obs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs):\n",
      "\u001b[0;31mObsIncompatibleError\u001b[0m: The requested obs ('Space',) are not compatible with the current obs ('mass_D', 'mass_eta')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Plot Projections\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43mplot_projection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_Ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_Ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs_D\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDs Sample: D Mass Projection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m plot_projection(model_Ds, data_Ds, obs_eta, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDs Sample: Eta Mass Projection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m plot_projection(model_Dp, data_Dp, obs_D, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD+ Sample: D Mass Projection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 29\u001b[0m, in \u001b[0;36mplot_projection\u001b[0;34m(model, data, obs, title, bins)\u001b[0m\n\u001b[1;32m     24\u001b[0m plot_range \u001b[38;5;241m=\u001b[39m (xmin, xmax)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# 2. Extract Data\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Use the observable name to access the column safely\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# .numpy() returns shape (N, 1), so we flatten it to shape (N,)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m data_np \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# 3. Histogram Data\u001b[39;00m\n\u001b[1;32m     32\u001b[0m Y, X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(data_np, bins\u001b[38;5;241m=\u001b[39mbins, \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39mplot_range)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/zfit/core/data.py:1118\u001b[0m, in \u001b[0;36mData.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m errorobs:\n\u001b[1;32m   1113\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1114\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to retrieve \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from data \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This can be changed behavior (since zfit 0.11): data can\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1115\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m no longer be accessed numpy-like but instead the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m can be used, i.e. strings or spaces. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1116\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m resembles more closely the behavior of a pandas DataFrame.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1117\u001b[0m     )\n\u001b[0;32m-> 1118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merrorobs\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to retrieve Space from data zfit.Data: Data obs=('mass_D', 'mass_eta') array=[[1948.64883459  505.84774331]\n [1801.87606257  552.86804195]\n [1969.01277722  556.33975977]\n ...\n [1958.25940443  551.5021189 ]\n [2051.10416549  527.25011039]\n [1952.83044287  585.82124203]]. This can be changed behavior (since zfit 0.11): data can no longer be accessed numpy-like but instead the 'obs' can be used, i.e. strings or spaces. This resembles more closely the behavior of a pandas DataFrame."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Results & Plotting\n",
    "# ==========================================\n",
    "\n",
    "br_val = result.params[br_eta_mumu]['value']\n",
    "br_err = result.params[br_eta_mumu]['hesse']['error']\n",
    "\n",
    "print(f\"\\n\" + \"=\"*40)\n",
    "print(f\"True BR:   {BR_true:.2e}\")\n",
    "print(f\"Fitted BR: {br_val:.2e} +/- {br_err:.2e}\")\n",
    "print(f\"Dev (sig): {(br_val - BR_true)/br_err:.2f} sigma\")\n",
    "print(\"=\"*40 + \"\\n\")\n",
    "\n",
    "# --- Plotting Function ---\n",
    "def plot_projection(model, data, obs, title, bins=40):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # 1. Robustly extract limits\n",
    "    # obs.rect_limits returns (lower_array, upper_array)\n",
    "    lower, upper = obs.rect_limits\n",
    "    # Convert to standard python floats to avoid numpy shape issues\n",
    "    xmin = float(np.array(lower).flatten()[0])\n",
    "    xmax = float(np.array(upper).flatten()[0])\n",
    "    plot_range = (xmin, xmax)\n",
    "\n",
    "    # 2. Extract Data\n",
    "    # Use the observable name to access the column safely\n",
    "    # .numpy() returns shape (N, 1), so we flatten it to shape (N,)\n",
    "    data_np = data[obs.name].numpy().flatten()\n",
    "\n",
    "    # 3. Histogram Data\n",
    "    Y, X = np.histogram(data_np, bins=bins, range=plot_range)\n",
    "    X_centers = (X[1:] + X[:-1])/2\n",
    "    err = np.sqrt(Y)\n",
    "    plt.errorbar(X_centers, Y, yerr=err, fmt='k.', label=\"Data\")\n",
    "    \n",
    "    # 4. Model Projection\n",
    "    x_plot = np.linspace(xmin, xmax, 200)\n",
    "    \n",
    "    # Create projection on the specific observable\n",
    "    model_proj = model.create_projection(obs)\n",
    "    y_pdf = model_proj.pdf(x_plot).numpy()\n",
    "    \n",
    "    # 5. Scale the PDF\n",
    "    # For extended fits, the pdf is normalized to 1, so we scale by Yield * BinWidth.\n",
    "    # We try to get the fitted yield from the model; fallback to data count if needed.\n",
    "    try:\n",
    "        # Attempt to get the integral of the extended model\n",
    "        total_yield = model.get_yield().numpy()\n",
    "    except:\n",
    "        # Fallback if model structure is complex\n",
    "        total_yield = data.n_events.numpy()\n",
    "\n",
    "    bin_width = (xmax - xmin) / bins\n",
    "    y_plot = y_pdf * total_yield * bin_width\n",
    "    \n",
    "    plt.plot(x_plot, y_plot, 'b-', label=\"Total Fit\")\n",
    "    plt.xlabel(obs.name)\n",
    "    plt.ylabel(\"Events\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "# Plot Projections\n",
    "plot_projection(model_Ds, data_Ds, obs_D, \"Ds Sample: D Mass Projection\")\n",
    "plot_projection(model_Ds, data_Ds, obs_eta, \"Ds Sample: Eta Mass Projection\")\n",
    "\n",
    "plot_projection(model_Dp, data_Dp, obs_D, \"D+ Sample: D Mass Projection\")\n",
    "plot_projection(model_Dp, data_Dp, obs_eta, \"D+ Sample: Eta Mass Projection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58f27bd-558e-4786-a6d4-c50b49f51acd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my-local-env)",
   "language": "python",
   "name": "my-local-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
